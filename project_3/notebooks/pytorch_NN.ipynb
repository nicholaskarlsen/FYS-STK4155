{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd.functional import hessian, jacobian\n",
    "from torchviz import make_dot\n",
    "\n",
    "sys.path.insert(0, \"../src\")\n",
    "from utils import minibatch, u_analytic\n",
    "\n",
    "dtype = torch.float\n",
    "#device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_trial(x, t, N):\n",
    "    return (1 - t) * torch.sin(np.pi * x) + x * (1 - x) * t * N\n",
    "\n",
    "#@torch.jit.script\n",
    "def ode_loss(input_data, output_data):\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(input_data.size(0)):\n",
    "        Jx, Jt, Jn = jacobian(g_trial, (input_data[i,0], input_data[i,1], output_data[i]),create_graph=True)\n",
    "        Hx, Ht, Hn = hessian(g_trial, (input_data[i,0], input_data[i,1], output_data[i]),create_graph=True)\n",
    "        loss = loss + (Jt - Hx[0]).pow(2)\n",
    "    \n",
    "    return loss / input_data.size(0)\n",
    "\n",
    "def g_trial_np(x, t, N):\n",
    "    return (1 - t) * np.sin(np.pi * x) + x * (1 - x) * t * N\n",
    "\n",
    "def plot_pde(model, grid_size=100):\n",
    "    # Set up plotting data\n",
    "    x = np.linspace(0,1,grid_size, dtype=np.float)\n",
    "    t = np.linspace(0,1,grid_size, dtype=np.float)\n",
    "    x, t = np.meshgrid(x, t) \n",
    "    x_flat = x.flatten()\n",
    "    t_flat = t.flatten()\n",
    "    X = np.concatenate((x_flat.reshape(-1,1), t_flat.reshape(-1, 1)), axis=1)\n",
    "\n",
    "    # Convert to pytorch tensors\n",
    "    xp = torch.from_numpy(X)\n",
    "    xp = xp.to(dtype).to(device)\n",
    "    \n",
    "    # Evaluate model\n",
    "    model.eval()    \n",
    "    N_pred = model(xp)\n",
    "    N_pred = N_pred.detach().numpy()\n",
    "    N_pred = N_pred.reshape(grid_size, grid_size)\n",
    "\n",
    "    g = g_trial_np(x, t, N_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    cf = ax.pcolormesh(x, t, g, cmap=plt.get_cmap(\"inferno\"))\n",
    "    fig.colorbar(cf, ax=ax)\n",
    "    ax.set_xlabel(\"$x$\")\n",
    "    ax.set_ylabel(\"$t$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on a 10x10 Grid\n",
    "\n",
    "We first train a model on an equispaced 10x10 grid using a FFNN with 2 hidden layers with 100 neurons each and the ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data in numpy\n",
    "grid_size = 10\n",
    "x = np.linspace(0,1,grid_size, dtype=np.float)\n",
    "t = np.linspace(0,1,grid_size, dtype=np.float)\n",
    "x, t = np.meshgrid(x, t) \n",
    "x = x.flatten()\n",
    "t = t.flatten()\n",
    "X = np.concatenate((x.reshape(-1,1), t.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Convert to pytorch tensors\n",
    "x = torch.from_numpy(X)\n",
    "x = x.to(dtype).to(device)\n",
    "x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the network\n",
    "num_points, input_dim = X.shape\n",
    "hidden_neurons = 100\n",
    "output_dim = 1\n",
    "\n",
    "# Set up the model\n",
    "learning_rate = 0.002\n",
    "N_minibatches = int(num_points / 16)\n",
    "\n",
    "model_10 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_dim, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, output_dim),\n",
    ")\n",
    "optimizer_10 = torch.optim.Adam(model_10.parameters(), lr=learning_rate)\n",
    "\n",
    "TOT_EPOCHS_10 = 0\n",
    "\n",
    "loss_arr_tot_10 = np.empty(0, dtype=np.float)\n",
    "epoch_arr_tot_10 = np.empty(0, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500: loss =  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "501: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "502: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "503: loss =  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "504: loss =  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "505: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "506: loss =  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "507: loss =  tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "508: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "509: loss =  tensor([0.0033], grad_fn=<DivBackward0>)\n",
      "510: loss =  tensor([0.0025], grad_fn=<DivBackward0>)\n",
      "511: loss =  tensor([0.0053], grad_fn=<DivBackward0>)\n",
      "512: loss =  tensor([0.0031], grad_fn=<DivBackward0>)\n",
      "513: loss =  tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "514: loss =  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "515: loss =  tensor([0.0027], grad_fn=<DivBackward0>)\n",
      "516: loss =  tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "517: loss =  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "518: loss =  tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "519: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "520: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "521: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "522: loss =  tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "523: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "524: loss =  tensor([0.0026], grad_fn=<DivBackward0>)\n",
      "525: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "526: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "527: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "528: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "529: loss =  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "530: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "531: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "532: loss =  tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "533: loss =  tensor([0.0036], grad_fn=<DivBackward0>)\n",
      "534: loss =  tensor([0.0148], grad_fn=<DivBackward0>)\n",
      "535: loss =  tensor([0.0093], grad_fn=<DivBackward0>)\n",
      "536: loss =  tensor([0.0107], grad_fn=<DivBackward0>)\n",
      "537: loss =  tensor([0.0080], grad_fn=<DivBackward0>)\n",
      "538: loss =  tensor([0.0110], grad_fn=<DivBackward0>)\n",
      "539: loss =  tensor([0.0031], grad_fn=<DivBackward0>)\n",
      "540: loss =  tensor([0.0064], grad_fn=<DivBackward0>)\n",
      "541: loss =  tensor([0.0063], grad_fn=<DivBackward0>)\n",
      "542: loss =  tensor([0.0052], grad_fn=<DivBackward0>)\n",
      "543: loss =  tensor([0.0018], grad_fn=<DivBackward0>)\n",
      "544: loss =  tensor([0.0044], grad_fn=<DivBackward0>)\n",
      "545: loss =  tensor([0.0098], grad_fn=<DivBackward0>)\n",
      "546: loss =  tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "547: loss =  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "548: loss =  tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "549: loss =  tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "550: loss =  tensor([0.0050], grad_fn=<DivBackward0>)\n",
      "551: loss =  tensor([0.0063], grad_fn=<DivBackward0>)\n",
      "552: loss =  tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "553: loss =  tensor([0.0036], grad_fn=<DivBackward0>)\n",
      "554: loss =  tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "555: loss =  tensor([0.0047], grad_fn=<DivBackward0>)\n",
      "556: loss =  tensor([0.0078], grad_fn=<DivBackward0>)\n",
      "557: loss =  tensor([0.0054], grad_fn=<DivBackward0>)\n",
      "558: loss =  tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "559: loss =  tensor([0.0021], grad_fn=<DivBackward0>)\n",
      "560: loss =  tensor([0.0043], grad_fn=<DivBackward0>)\n",
      "561: loss =  tensor([0.0040], grad_fn=<DivBackward0>)\n",
      "562: loss =  tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "563: loss =  tensor([0.0274], grad_fn=<DivBackward0>)\n",
      "564: loss =  tensor([0.0068], grad_fn=<DivBackward0>)\n",
      "565: loss =  tensor([0.0177], grad_fn=<DivBackward0>)\n",
      "566: loss =  tensor([0.0179], grad_fn=<DivBackward0>)\n",
      "567: loss =  tensor([0.0269], grad_fn=<DivBackward0>)\n",
      "568: loss =  tensor([0.0059], grad_fn=<DivBackward0>)\n",
      "569: loss =  tensor([0.0089], grad_fn=<DivBackward0>)\n",
      "570: loss =  tensor([0.0290], grad_fn=<DivBackward0>)\n",
      "571: loss =  tensor([0.0115], grad_fn=<DivBackward0>)\n",
      "572: loss =  tensor([0.0087], grad_fn=<DivBackward0>)\n",
      "573: loss =  tensor([0.0061], grad_fn=<DivBackward0>)\n",
      "574: loss =  tensor([0.0123], grad_fn=<DivBackward0>)\n",
      "575: loss =  tensor([0.0075], grad_fn=<DivBackward0>)\n",
      "576: loss =  tensor([0.0550], grad_fn=<DivBackward0>)\n",
      "577: loss =  tensor([0.0621], grad_fn=<DivBackward0>)\n",
      "578: loss =  tensor([0.0192], grad_fn=<DivBackward0>)\n",
      "579: loss =  tensor([0.1023], grad_fn=<DivBackward0>)\n",
      "580: loss =  tensor([0.0905], grad_fn=<DivBackward0>)\n",
      "581: loss =  tensor([0.1062], grad_fn=<DivBackward0>)\n",
      "582: loss =  tensor([0.0271], grad_fn=<DivBackward0>)\n",
      "583: loss =  tensor([0.0392], grad_fn=<DivBackward0>)\n",
      "584: loss =  tensor([0.0320], grad_fn=<DivBackward0>)\n",
      "585: loss =  tensor([0.0157], grad_fn=<DivBackward0>)\n",
      "586: loss =  tensor([0.0324], grad_fn=<DivBackward0>)\n",
      "587: loss =  tensor([0.0382], grad_fn=<DivBackward0>)\n",
      "588: loss =  tensor([0.0046], grad_fn=<DivBackward0>)\n",
      "589: loss =  tensor([0.0074], grad_fn=<DivBackward0>)\n",
      "590: loss =  tensor([0.0098], grad_fn=<DivBackward0>)\n",
      "591: loss =  tensor([0.0072], grad_fn=<DivBackward0>)\n",
      "592: loss =  tensor([0.0045], grad_fn=<DivBackward0>)\n",
      "593: loss =  tensor([0.0050], grad_fn=<DivBackward0>)\n",
      "594: loss =  tensor([0.0026], grad_fn=<DivBackward0>)\n",
      "595: loss =  tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "596: loss =  tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "597: loss =  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "598: loss =  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "599: loss =  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "600: loss =  tensor([0.0024], grad_fn=<DivBackward0>)\n",
      "601: loss =  tensor([0.0027], grad_fn=<DivBackward0>)\n",
      "602: loss =  tensor([0.0025], grad_fn=<DivBackward0>)\n",
      "603: loss =  tensor([0.0013], grad_fn=<DivBackward0>)\n",
      "604: loss =  tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "605: loss =  tensor([0.0029], grad_fn=<DivBackward0>)\n",
      "606: loss =  tensor([0.0025], grad_fn=<DivBackward0>)\n",
      "607: loss =  tensor([0.0019], grad_fn=<DivBackward0>)\n",
      "608: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "609: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "610: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "611: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "612: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "613: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "614: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "615: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "616: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "617: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "618: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "619: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "620: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "621: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "622: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "623: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "624: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "625: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "626: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "627: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "628: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "629: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "630: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "631: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "632: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "633: loss =  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "634: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "635: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "636: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "637: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "638: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "639: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "640: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "641: loss =  tensor([0.0013], grad_fn=<DivBackward0>)\n",
      "642: loss =  tensor([0.0023], grad_fn=<DivBackward0>)\n",
      "643: loss =  tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "644: loss =  tensor([0.0036], grad_fn=<DivBackward0>)\n",
      "645: loss =  tensor([0.0027], grad_fn=<DivBackward0>)\n",
      "646: loss =  tensor([0.0042], grad_fn=<DivBackward0>)\n",
      "647: loss =  tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "648: loss =  tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "649: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "650: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "651: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "653: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "654: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "655: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "656: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "657: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "658: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "659: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "660: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "661: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "662: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "663: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "664: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "665: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "666: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "667: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "668: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "669: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "670: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "671: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "672: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "673: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "674: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "675: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "676: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "677: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "678: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "679: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "680: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "681: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "682: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "683: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "684: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "685: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "686: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "687: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "688: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "689: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "690: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "691: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "692: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "693: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "694: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "695: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "696: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "697: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "698: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "699: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "700: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "701: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "702: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "703: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "704: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "705: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "706: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "707: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "708: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "709: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "710: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "711: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "712: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "713: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "714: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "715: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "716: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "717: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "718: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "719: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "720: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "721: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "722: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "723: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "724: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "725: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "726: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "727: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "728: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "729: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "730: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "731: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "732: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "733: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "734: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "735: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "736: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "737: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "738: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "739: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "740: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "741: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "742: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "743: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "744: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "745: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "746: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "747: loss =  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "748: loss =  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "749: loss =  tensor([0.0027], grad_fn=<DivBackward0>)\n",
      "750: loss =  tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "751: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "752: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "753: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "754: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "755: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "756: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "757: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "758: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "759: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "760: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "761: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "762: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "763: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "764: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "765: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "766: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "767: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "768: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "769: loss =  tensor([0.0018], grad_fn=<DivBackward0>)\n",
      "770: loss =  tensor([0.0061], grad_fn=<DivBackward0>)\n",
      "771: loss =  tensor([0.0069], grad_fn=<DivBackward0>)\n",
      "772: loss =  tensor([0.0032], grad_fn=<DivBackward0>)\n",
      "773: loss =  tensor([0.0078], grad_fn=<DivBackward0>)\n",
      "774: loss =  tensor([0.0166], grad_fn=<DivBackward0>)\n",
      "775: loss =  tensor([0.0063], grad_fn=<DivBackward0>)\n",
      "776: loss =  tensor([0.0024], grad_fn=<DivBackward0>)\n",
      "777: loss =  tensor([0.0046], grad_fn=<DivBackward0>)\n",
      "778: loss =  tensor([0.0062], grad_fn=<DivBackward0>)\n",
      "779: loss =  tensor([0.0025], grad_fn=<DivBackward0>)\n",
      "780: loss =  tensor([0.0036], grad_fn=<DivBackward0>)\n",
      "781: loss =  tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "782: loss =  tensor([0.0121], grad_fn=<DivBackward0>)\n",
      "783: loss =  tensor([0.0186], grad_fn=<DivBackward0>)\n",
      "784: loss =  tensor([0.0145], grad_fn=<DivBackward0>)\n",
      "785: loss =  tensor([0.0188], grad_fn=<DivBackward0>)\n",
      "786: loss =  tensor([0.0048], grad_fn=<DivBackward0>)\n",
      "787: loss =  tensor([0.0073], grad_fn=<DivBackward0>)\n",
      "788: loss =  tensor([0.0057], grad_fn=<DivBackward0>)\n",
      "789: loss =  tensor([0.0157], grad_fn=<DivBackward0>)\n",
      "790: loss =  tensor([0.0124], grad_fn=<DivBackward0>)\n",
      "791: loss =  tensor([0.0105], grad_fn=<DivBackward0>)\n",
      "792: loss =  tensor([0.0077], grad_fn=<DivBackward0>)\n",
      "793: loss =  tensor([0.0091], grad_fn=<DivBackward0>)\n",
      "794: loss =  tensor([0.0174], grad_fn=<DivBackward0>)\n",
      "795: loss =  tensor([0.0051], grad_fn=<DivBackward0>)\n",
      "796: loss =  tensor([0.0035], grad_fn=<DivBackward0>)\n",
      "797: loss =  tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "798: loss =  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "799: loss =  tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "800: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "801: loss =  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "802: loss =  tensor([0.0027], grad_fn=<DivBackward0>)\n",
      "803: loss =  tensor([0.0013], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804: loss =  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "805: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "806: loss =  tensor([0.0024], grad_fn=<DivBackward0>)\n",
      "807: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "808: loss =  tensor([0.0036], grad_fn=<DivBackward0>)\n",
      "809: loss =  tensor([0.0018], grad_fn=<DivBackward0>)\n",
      "810: loss =  tensor([0.0019], grad_fn=<DivBackward0>)\n",
      "811: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "812: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "813: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "814: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "815: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "816: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "817: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "818: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "819: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "820: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "821: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "822: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "823: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "824: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "825: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "826: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "827: loss =  tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "828: loss =  tensor([0.0018], grad_fn=<DivBackward0>)\n",
      "829: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "830: loss =  tensor([0.0054], grad_fn=<DivBackward0>)\n",
      "831: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "832: loss =  tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "833: loss =  tensor([0.0013], grad_fn=<DivBackward0>)\n",
      "834: loss =  tensor([0.0100], grad_fn=<DivBackward0>)\n",
      "835: loss =  tensor([0.0064], grad_fn=<DivBackward0>)\n",
      "836: loss =  tensor([0.0034], grad_fn=<DivBackward0>)\n",
      "837: loss =  tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "838: loss =  tensor([0.0021], grad_fn=<DivBackward0>)\n",
      "839: loss =  tensor([0.0013], grad_fn=<DivBackward0>)\n",
      "840: loss =  tensor([0.0027], grad_fn=<DivBackward0>)\n",
      "841: loss =  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "842: loss =  tensor([0.0043], grad_fn=<DivBackward0>)\n",
      "843: loss =  tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "844: loss =  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "845: loss =  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "846: loss =  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "847: loss =  tensor([0.0027], grad_fn=<DivBackward0>)\n",
      "848: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "849: loss =  tensor([0.0047], grad_fn=<DivBackward0>)\n",
      "850: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "851: loss =  tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "852: loss =  tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "853: loss =  tensor([0.0041], grad_fn=<DivBackward0>)\n",
      "854: loss =  tensor([0.0162], grad_fn=<DivBackward0>)\n",
      "855: loss =  tensor([0.0156], grad_fn=<DivBackward0>)\n",
      "856: loss =  tensor([0.0140], grad_fn=<DivBackward0>)\n",
      "857: loss =  tensor([0.0019], grad_fn=<DivBackward0>)\n",
      "858: loss =  tensor([0.0071], grad_fn=<DivBackward0>)\n",
      "859: loss =  tensor([0.0045], grad_fn=<DivBackward0>)\n",
      "860: loss =  tensor([0.0063], grad_fn=<DivBackward0>)\n",
      "861: loss =  tensor([0.0035], grad_fn=<DivBackward0>)\n",
      "862: loss =  tensor([0.0052], grad_fn=<DivBackward0>)\n",
      "863: loss =  tensor([0.0159], grad_fn=<DivBackward0>)\n",
      "864: loss =  tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "865: loss =  tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "866: loss =  tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "867: loss =  tensor([0.0042], grad_fn=<DivBackward0>)\n",
      "868: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "869: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "870: loss =  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "871: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "872: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "873: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "874: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "875: loss =  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "876: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "877: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "878: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "879: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "880: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "881: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "882: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "883: loss =  tensor([0.0013], grad_fn=<DivBackward0>)\n",
      "884: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "885: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "886: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "887: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "888: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "889: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "890: loss =  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "891: loss =  tensor([0.0019], grad_fn=<DivBackward0>)\n",
      "892: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "893: loss =  tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "894: loss =  tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "895: loss =  tensor([0.0083], grad_fn=<DivBackward0>)\n",
      "896: loss =  tensor([0.0134], grad_fn=<DivBackward0>)\n",
      "897: loss =  tensor([0.0070], grad_fn=<DivBackward0>)\n",
      "898: loss =  tensor([0.0124], grad_fn=<DivBackward0>)\n",
      "899: loss =  tensor([0.0035], grad_fn=<DivBackward0>)\n",
      "900: loss =  tensor([0.0235], grad_fn=<DivBackward0>)\n",
      "901: loss =  tensor([0.0515], grad_fn=<DivBackward0>)\n",
      "902: loss =  tensor([0.0848], grad_fn=<DivBackward0>)\n",
      "903: loss =  tensor([0.1334], grad_fn=<DivBackward0>)\n",
      "904: loss =  tensor([0.1191], grad_fn=<DivBackward0>)\n",
      "905: loss =  tensor([0.2531], grad_fn=<DivBackward0>)\n",
      "906: loss =  tensor([0.2763], grad_fn=<DivBackward0>)\n",
      "907: loss =  tensor([0.0712], grad_fn=<DivBackward0>)\n",
      "908: loss =  tensor([0.0331], grad_fn=<DivBackward0>)\n",
      "909: loss =  tensor([0.0251], grad_fn=<DivBackward0>)\n",
      "910: loss =  tensor([0.0209], grad_fn=<DivBackward0>)\n",
      "911: loss =  tensor([0.0117], grad_fn=<DivBackward0>)\n",
      "912: loss =  tensor([0.0081], grad_fn=<DivBackward0>)\n",
      "913: loss =  tensor([0.0048], grad_fn=<DivBackward0>)\n",
      "914: loss =  tensor([0.0048], grad_fn=<DivBackward0>)\n",
      "915: loss =  tensor([0.0054], grad_fn=<DivBackward0>)\n",
      "916: loss =  tensor([0.0050], grad_fn=<DivBackward0>)\n",
      "917: loss =  tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "918: loss =  tensor([0.0032], grad_fn=<DivBackward0>)\n",
      "919: loss =  tensor([0.0021], grad_fn=<DivBackward0>)\n",
      "920: loss =  tensor([0.0019], grad_fn=<DivBackward0>)\n",
      "921: loss =  tensor([0.0028], grad_fn=<DivBackward0>)\n",
      "922: loss =  tensor([0.0048], grad_fn=<DivBackward0>)\n",
      "923: loss =  tensor([0.0055], grad_fn=<DivBackward0>)\n",
      "924: loss =  tensor([0.0031], grad_fn=<DivBackward0>)\n",
      "925: loss =  tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "926: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "927: loss =  tensor([0.0018], grad_fn=<DivBackward0>)\n",
      "928: loss =  tensor([0.0018], grad_fn=<DivBackward0>)\n",
      "929: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "930: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "931: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "932: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "933: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "934: loss =  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "935: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "936: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "937: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "938: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "939: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "940: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "941: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "942: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "943: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "944: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "945: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "946: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "947: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "948: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "949: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "950: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "951: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "952: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "953: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "954: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "955: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "957: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "958: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "959: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "960: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "961: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "962: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "963: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "964: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "965: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "966: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "967: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "968: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "969: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "970: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "971: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "972: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "973: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "974: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "975: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "976: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "977: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "978: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "979: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "980: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "981: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "982: loss =  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "983: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "984: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "985: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "986: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "987: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "988: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "989: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "990: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "991: loss =  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "992: loss =  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "993: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "994: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "995: loss =  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "996: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "997: loss =  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "998: loss =  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "999: loss =  tensor([0.0015], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "\n",
    "loss_arr_curr_10 = np.empty(EPOCHS, dtype=np.float)\n",
    "epoch_arr_curr_10 = np.empty(EPOCHS, dtype=np.float)\n",
    "\n",
    "model_10.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    # Pick out a new set of minibatches\n",
    "    mb = minibatch(num_points, N_minibatches)\n",
    "    for i in range(N_minibatches):\n",
    "        N_output = model_10(x[mb[i]])           # Forward pass\n",
    "        loss = ode_loss(x[mb[i]], N_output)  # Compute loss\n",
    "        optimizer_10.zero_grad()                # Zero gradients from prev itter\n",
    "        loss.backward()                      # Backward pass\n",
    "        optimizer_10.step()                     # Optimize with ADAM\n",
    "        \n",
    "    # Compute loss of entire sample\n",
    "    N_output = model_10(x) \n",
    "    loss = ode_loss(x, N_output)\n",
    "    print(f\"{TOT_EPOCHS_10 + epoch}: loss = \",loss) \n",
    "    loss_arr_curr_10[epoch] = loss\n",
    "    epoch_arr_curr_10[epoch] = TOT_EPOCHS_10 + epoch\n",
    "\n",
    "TOT_EPOCHS_10 += EPOCHS    \n",
    "loss_arr_tot_10 = np.append(loss_arr_tot_10, loss_arr_curr_10)\n",
    "epoch_arr_tot_10 = np.append(epoch_arr_tot_10, epoch_arr_curr_10)\n",
    "\n",
    "plt.semilogy(epoch_arr_tot_10, loss_arr_tot_10)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-4c52362df4b0>:40: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  cf = ax.pcolormesh(x, t, g, cmap=plt.get_cmap(\"inferno\"))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pde(model_10, 10)\n",
    "plot_pde(model_10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#make_dot(N_output).render(\"output_graph\", format=\"pdf\")\n",
    "#make_dot(loss).render(\"loss_graph\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on a 100x100 Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data in numpy\n",
    "grid_size = 100\n",
    "x = np.linspace(0,1,grid_size, dtype=np.float)\n",
    "t = np.linspace(0,1,grid_size, dtype=np.float)\n",
    "x, t = np.meshgrid(x, t) \n",
    "x = x.flatten()\n",
    "t = t.flatten()\n",
    "X = np.concatenate((x.reshape(-1,1), t.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Convert to pytorch tensors\n",
    "x = torch.from_numpy(X)\n",
    "x = x.to(dtype).to(device)\n",
    "x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of minibatches =  625\n"
     ]
    }
   ],
   "source": [
    "# Shape of the network\n",
    "num_points, input_dim = X.shape\n",
    "hidden_neurons = 100\n",
    "output_dim = 1\n",
    "\n",
    "# Set up the model\n",
    "learning_rate = 0.002\n",
    "N_minibatches = int(num_points / 16)\n",
    "\n",
    "model_100 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_dim, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, output_dim),\n",
    ")\n",
    "optimizer_100 = torch.optim.Adam(model_100.parameters(), lr=learning_rate)\n",
    "\n",
    "TOT_EPOCHS_100 = 0\n",
    "\n",
    "loss_arr_tot_100 = np.empty(0, dtype=np.float)\n",
    "epoch_arr_tot_100 = np.empty(0, dtype=np.float)\n",
    "\n",
    "print(\"Number of minibatches = \", N_minibatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Gradient changes most rapidly at t ~ 0 to 0.2, so these areas will be most critical for the network to fit correclty. Later, less steeper parts of the function will likely have less of an effect on the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20: loss =  tensor([0.0108], grad_fn=<DivBackward0>)\n",
      "21: loss =  tensor([0.0035], grad_fn=<DivBackward0>)\n",
      "22: loss =  tensor([0.0026], grad_fn=<DivBackward0>)\n",
      "23: loss =  tensor([0.0075], grad_fn=<DivBackward0>)\n",
      "24: loss =  tensor([0.0079], grad_fn=<DivBackward0>)\n",
      "25: loss =  tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "26: loss =  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "27: loss =  tensor([0.0047], grad_fn=<DivBackward0>)\n",
      "28: loss =  tensor([0.0298], grad_fn=<DivBackward0>)\n",
      "29: loss =  tensor([0.0044], grad_fn=<DivBackward0>)\n",
      "30: loss =  tensor([0.0041], grad_fn=<DivBackward0>)\n",
      "31: loss =  tensor([0.0081], grad_fn=<DivBackward0>)\n",
      "32: loss =  tensor([0.0021], grad_fn=<DivBackward0>)\n",
      "33: loss =  tensor([0.0034], grad_fn=<DivBackward0>)\n",
      "34: loss =  tensor([0.0024], grad_fn=<DivBackward0>)\n",
      "35: loss =  tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "36: loss =  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "37: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "38: loss =  tensor([0.0025], grad_fn=<DivBackward0>)\n",
      "39: loss =  tensor([0.0041], grad_fn=<DivBackward0>)\n",
      "40: loss =  tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "41: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "42: loss =  tensor([0.0013], grad_fn=<DivBackward0>)\n",
      "43: loss =  tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "44: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "45: loss =  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "46: loss =  tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "47: loss =  tensor([0.0057], grad_fn=<DivBackward0>)\n",
      "48: loss =  tensor([0.0013], grad_fn=<DivBackward0>)\n",
      "49: loss =  tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "50: loss =  tensor([0.0074], grad_fn=<DivBackward0>)\n",
      "51: loss =  tensor([0.0021], grad_fn=<DivBackward0>)\n",
      "52: loss =  tensor([0.0125], grad_fn=<DivBackward0>)\n",
      "53: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "54: loss =  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "55: loss =  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "56: loss =  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "57: loss =  tensor([0.0116], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-aaa27939db5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Compute loss of entire sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mN_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_100\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mode_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{TOT_EPOCHS_100 + epoch}: loss = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss_arr_curr_100\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4c52362df4b0>\u001b[0m in \u001b[0;36mode_loss\u001b[0;34m(input_data, output_data)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mJx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mHx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mJt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mHx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mjac_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             vj = _autograd_grad((out.reshape(-1)[j],), inputs,\n\u001b[0m\u001b[1;32m    438\u001b[0m                                 retain_graph=True, create_graph=create_graph)\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         return torch.autograd.grad(new_outputs, inputs, new_grad_outputs, allow_unused=True,\n\u001b[0m\u001b[1;32m    147\u001b[0m                                    create_graph=create_graph, retain_graph=retain_graph)\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         inputs, allow_unused)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "loss_arr_curr_100 = np.empty(EPOCHS, dtype=np.float)\n",
    "epoch_arr_curr_100 = np.empty(EPOCHS, dtype=np.float)\n",
    "\n",
    "model_100.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    # Pick out a new set of minibatches\n",
    "    mb = minibatch(num_points, N_minibatches)\n",
    "    for i in range(N_minibatches):\n",
    "        N_output = model_100(x[mb[i]])           # Forward pass\n",
    "        loss = ode_loss(x[mb[i]], N_output)  # Compute loss\n",
    "        optimizer_100.zero_grad()                # Zero gradients from prev itter\n",
    "        loss.backward()                      # Backward pass\n",
    "        optimizer_100.step()                     # Optimize with ADAM\n",
    "        \n",
    "    # Compute loss of entire sample\n",
    "    N_output = model_100(x) \n",
    "    loss = ode_loss(x, N_output)\n",
    "    print(f\"{TOT_EPOCHS_100 + epoch}: loss = \",loss) \n",
    "    loss_arr_curr_100[epoch] = loss\n",
    "    epoch_arr_curr_100[epoch] = TOT_EPOCHS_100 + epoch\n",
    "\n",
    "TOT_EPOCHS_100 += EPOCHS    \n",
    "loss_arr_tot_100 = np.append(loss_arr_tot_100, loss_arr_curr_100)\n",
    "epoch_arr_tot_100 = np.append(epoch_arr_tot_100, epoch_arr_curr_100)\n",
    "\n",
    "plt.semilogy(epoch_arr_tot_100, loss_arr_tot_100)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pde(model=model_100, grid_size=10)\n",
    "plot_pde(model=model_100, grid_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
