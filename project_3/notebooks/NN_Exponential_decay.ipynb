{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import grad\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../../project_2/src\")\n",
    "\n",
    "import CostFunctions as cfunc\n",
    "import NeuralNetwork as NN\n",
    "import ActivationFunctions as afunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the ODE\n",
    "$$g'(x) = -\\gamma(x)$$\n",
    "with analytic solution\n",
    "$$g(x) = -g_0 \\exp(-\\gamma x)$$\n",
    "\n",
    "with $g_0=1, \\gamma = 10$ for $x \\in [0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f71a739df70>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0, 1, 100)\n",
    "gamma = 10\n",
    "g0 = 1\n",
    "g = lambda x : g0 * np.exp(- gamma * x)\n",
    "plt.plot(x, g(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can rewrite the ODE as\n",
    "$$ g'(t) + \\gamma g(t) = 0$$\n",
    "yielding the cost function\n",
    "$$C[g] = \\frac{1}{N} \\sum_{i=1}^N (g'(t) + \\gamma g(t))^2$$\n",
    "\n",
    "Propose a trial solution in the form\n",
    "$$ g_t(t) = g_0 + x \\cdot N(t, \\{\\pmb w\\}, \\{\\pmb b\\})$$\n",
    "\n",
    "$\\implies g_t(x=0) = g_0$, initial condition is satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODE_exponential_growth(cfunc.CostFunction):\n",
    "    \n",
    "    def evaluate_gradient(model, data):\n",
    "        u_trial = g0 + data * model\n",
    "        dudx = grad(g0 + data * model)\n",
    "        return np.sum(dudx(data) + (gamma))**2\n",
    "    \n",
    "    \n",
    "# The cost function:\n",
    "def cost_function(P, x):\n",
    "\n",
    "    # Evaluate the trial function with the current parameters P\n",
    "    g_t = g_trial(x,P)\n",
    "\n",
    "    # Find the derivative w.r.t x of the neural network\n",
    "    d_net_out = elementwise_grad(neural_network,1)(P,x)\n",
    "\n",
    "    # Find the derivative w.r.t x of the trial function\n",
    "    d_g_t = elementwise_grad(g_trial,0)(x,P)\n",
    "\n",
    "    # The right side of the ODE\n",
    "    func = g(x, g_t)\n",
    "\n",
    "    err_sqr = (d_g_t - func)**2\n",
    "    cost_sum = np.sum(err_sqr)\n",
    "\n",
    "    return cost_sum / np.size(err_sqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'activation_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3b693a82904a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m FFNN = NN.FeedForwardNeuralNetwork(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnetwork_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'activation_out'"
     ]
    }
   ],
   "source": [
    "FFNN = NN.FeedForwardNeuralNetwork(\n",
    "    X = np.linspace(0, 1, 100).reshape(-1, 1),\n",
    "    Y = np.linspace(0, 1, 100).reshape(-1, 1),\n",
    "    network_shape = [100],\n",
    "    activation = afunc.ReLU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.6981, 1.3963, 2.0944, 2.7925, 3.4907, 4.1888, 4.8869, 5.5851,\n",
      "        6.2832], requires_grad=True)\n",
      "tensor([ 0.0000,  0.4874,  1.9496,  4.3865,  7.7982, 12.1847, 17.5460, 23.8820,\n",
      "        31.1928, 39.4784], grad_fn=<PowBackward0>)\n",
      "tensor(3.1416, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "x = torch.linspace(0, 2*np.pi, 10, requires_grad=True)\n",
    "print(x)\n",
    "y = x ** 2\n",
    "print(y)\n",
    "z = torch.sqrt(y).mean()\n",
    "print(z)\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad, elementwise_grad\n",
    "import autograd.numpy.random as npr\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "# Assuming one input, hidden, and output layer\n",
    "def neural_network(params, x):\n",
    "\n",
    "    # Find the weights (including and biases) for the hidden and output layer.\n",
    "    # Assume that params is a list of parameters for each layer.\n",
    "    # The biases are the first element for each array in params,\n",
    "    # and the weights are the remaning elements in each array in params.\n",
    "\n",
    "    w_hidden = params[0]\n",
    "    w_output = params[1]\n",
    "\n",
    "    # Assumes input x being an one-dimensional array\n",
    "    num_values = np.size(x)\n",
    "    x = x.reshape(-1, num_values)\n",
    "\n",
    "    # Assume that the input layer does nothing to the input x\n",
    "    x_input = x\n",
    "\n",
    "    ## Hidden layer:\n",
    "\n",
    "    # Add a row of ones to include bias\n",
    "    x_input = np.concatenate((np.ones((1,num_values)), x_input ), axis = 0)\n",
    "\n",
    "    z_hidden = np.matmul(w_hidden, x_input)\n",
    "    x_hidden = sigmoid(z_hidden)\n",
    "\n",
    "    ## Output layer:\n",
    "\n",
    "    # Include bias:\n",
    "    x_hidden = np.concatenate((np.ones((1,num_values)), x_hidden ), axis = 0)\n",
    "\n",
    "    z_output = np.matmul(w_output, x_hidden)\n",
    "    x_output = z_output\n",
    "\n",
    "    return x_output\n",
    "\n",
    "# The trial solution using the deep neural network:\n",
    "def g_trial(x,params, g0 = 10):\n",
    "    return g0 + x*neural_network(params,x)\n",
    "\n",
    "# The right side of the ODE:\n",
    "def g(x, g_trial, gamma = 2):\n",
    "    return -gamma*g_trial\n",
    "\n",
    "# The cost function:\n",
    "def cost_function(P, x):\n",
    "\n",
    "    # Evaluate the trial function with the current parameters P\n",
    "    g_t = g_trial(x,P)\n",
    "\n",
    "    # Find the derivative w.r.t x of the neural network\n",
    "    d_net_out = elementwise_grad(neural_network,1)(P,x)\n",
    "\n",
    "    # Find the derivative w.r.t x of the trial function\n",
    "    d_g_t = elementwise_grad(g_trial,0)(x,P)\n",
    "\n",
    "    # The right side of the ODE\n",
    "    func = g(x, g_t)\n",
    "\n",
    "    err_sqr = (d_g_t - func)**2\n",
    "    cost_sum = np.sum(err_sqr)\n",
    "\n",
    "    return cost_sum / np.size(err_sqr)\n",
    "\n",
    "# Solve the exponential decay ODE using neural network with one input, hidden, and output layer\n",
    "def solve_ode_neural_network(x, num_neurons_hidden, num_iter, lmb):\n",
    "    ## Set up initial weights and biases\n",
    "\n",
    "    # For the hidden layer\n",
    "    p0 = npr.randn(num_neurons_hidden, 2 )\n",
    "\n",
    "    # For the output layer\n",
    "    p1 = npr.randn(1, num_neurons_hidden + 1 ) # +1 since bias is included\n",
    "\n",
    "    P = [p0, p1]\n",
    "\n",
    "    print('Initial cost: %g'%cost_function(P, x))\n",
    "\n",
    "    ## Start finding the optimal weights using gradient descent\n",
    "\n",
    "    # Find the Python function that represents the gradient of the cost function\n",
    "    # w.r.t the 0-th input argument -- that is the weights and biases in the hidden and output layer\n",
    "    cost_function_grad = grad(cost_function,0)\n",
    "\n",
    "    # Let the update be done num_iter times\n",
    "    for i in range(num_iter):\n",
    "        # Evaluate the gradient at the current weights and biases in P.\n",
    "        # The cost_grad consist now of two arrays;\n",
    "        # one for the gradient w.r.t P_hidden and\n",
    "        # one for the gradient w.r.t P_output\n",
    "        cost_grad =  cost_function_grad(P, x)\n",
    "\n",
    "        P[0] = P[0] - lmb * cost_grad[0]\n",
    "        P[1] = P[1] - lmb * cost_grad[1]\n",
    "\n",
    "    print('Final cost: %g'%cost_function(P, x))\n",
    "\n",
    "    return P\n",
    "\n",
    "def g_analytic(x, gamma = 2, g0 = 10):\n",
    "    return g0*np.exp(-gamma*x)\n",
    "\n",
    "# Solve the given problem\n",
    "if __name__ == '__main__':\n",
    "    # Set seed such that the weight are initialized\n",
    "    # with same weights and biases for every run.\n",
    "    npr.seed(15)\n",
    "\n",
    "    ## Decide the vales of arguments to the function to solve\n",
    "    N = 10\n",
    "    x = np.linspace(0, 1, N)\n",
    "\n",
    "    ## Set up the initial parameters\n",
    "    num_hidden_neurons = 10\n",
    "    num_iter = 10000\n",
    "    lmb = 0.001\n",
    "\n",
    "    # Use the network\n",
    "    P = solve_ode_neural_network(x, num_hidden_neurons, num_iter, lmb)\n",
    "\n",
    "    # Print the deviation from the trial solution and true solution\n",
    "    res = g_trial(x,P)\n",
    "    res_analytical = g_analytic(x)\n",
    "\n",
    "    print('Max absolute difference: %g'%np.max(np.abs(res - res_analytical)))\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    plt.title('Performance of neural network solving an ODE compared to the analytical solution')\n",
    "    plt.plot(x, res_analytical)\n",
    "    plt.plot(x, res[0,:])\n",
    "    plt.legend(['analytical','nn'])\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('g(x)')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
