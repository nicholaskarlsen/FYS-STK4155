{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.insert(0,\"../src/\")\n",
    "import SGD\n",
    "import CostFunctions\n",
    "import SGDTEST as SGDTEST\n",
    "\n",
    "sys.path.insert(0,\"../../project_1/src/\")\n",
    "from FrankeFunction import *\n",
    "import stat_tools\n",
    "import linear_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500                # Number of data points\n",
    "noise_scale = 0.2      # Size of artificial noise\n",
    "\n",
    "\n",
    "\n",
    "# Generate data\n",
    "x = np.random.uniform(0, 10, n)\n",
    "y = np.random.uniform(0, 10, n)\n",
    "z = 4*x**3 - 20*y**2\n",
    "# z = FrankeFunction(x, y)\n",
    "\n",
    "# Add standard normal noise:\n",
    "#z = z + noise_scale * np.random.normal(0, 1, len(z))\n",
    "x_train, x_test, y_train, y_test, z_train, z_test = train_test_split(x, y, z, test_size=0.2)\n",
    "\n",
    "# Center the response \n",
    "z_train_intercept = np.mean(z_train)\n",
    "z_train = z_train - z_train_intercept\n",
    "z_test = z_test - z_train_intercept\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.12638804e-13  5.40012479e-13  2.04636308e-12 -1.13686838e-13\n",
      " -5.82055047e+02  1.13766490e+03  5.68434189e-13 -2.27373675e-13\n",
      "  6.96331881e-13]\n",
      "[-109.10063788 -130.8370166   389.54596538  -79.97278347 -238.44141305\n",
      "  835.4051875   115.1562309   -45.86182382 -189.45868594]\n",
      "[-109.07702417 -130.83644086  389.61823795  -79.99625089 -238.41102265\n",
      "  835.46542267  115.09656487  -45.80075932 -189.53437111]\n"
     ]
    }
   ],
   "source": [
    "# Create design matrices\n",
    "degree = 3\n",
    "X_train = linear_regression.design_matrix_2D(x_train, y_train, degree)\n",
    "X_test = linear_regression.design_matrix_2D(x_test, y_test, degree)\n",
    "\n",
    "# Scale design matrix according to the training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Remove the intercept\n",
    "X_train_scaled = X_train_scaled[:,1:]\n",
    "X_test_scaled = X_test_scaled[:,1:]\n",
    "\n",
    "N_predictors = int((degree + 1) * (degree + 2) / 2) - 1 # Don't include intercept\n",
    "w_init = np.random.randn(N_predictors) # Random initial weights\n",
    "#w_init = [4,-2]\n",
    "\n",
    "M = int(n/100)                 # Number of mini-batches in SGD\n",
    "n_epochs = int(1e5)        # Number of epochs in SGD\n",
    "learning_rate = 0.0001 # Learning rate of SGD\n",
    "\n",
    "\n",
    "# Solve for optimal weights using OLS Cost function\n",
    "w_OLS_Analytic = linear_regression.OLS_SVD_2D(X_train_scaled, z_train)\n",
    "\n",
    "# weights from SGD\n",
    "\n",
    "w_OLS_SGD = SGD.SGD(\n",
    "    X_train_scaled, \n",
    "    z_train, \n",
    "    M, \n",
    "    w_init, \n",
    "    n_epochs, \n",
    "    learning_rate, \n",
    "    CostFunctions.OLS_cost_gradient)\n",
    "\n",
    "w_OLS_SGD_TEST = SGDTEST.SGD(\n",
    "    X_train_scaled, \n",
    "    z_train, \n",
    "    M, \n",
    "    w_init, \n",
    "    n_epochs, \n",
    "    learning_rate, \n",
    "    CostFunctions.OLS_cost_gradient)\n",
    "\n",
    "print(w_OLS_Analytic)\n",
    "print(w_OLS_SGD)\n",
    "print(w_OLS_SGD_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.962320063617306e-24\n",
      "773.3257131679987\n",
      "773.5072631634798\n",
      "1.8402037277306628e-24\n",
      "962.3299152010176\n",
      "962.6600788097523\n"
     ]
    }
   ],
   "source": [
    "print(stat_tools.MSE(z_train,X_train_scaled @ w_OLS_Analytic))\n",
    "print(stat_tools.MSE(z_train,X_train_scaled @ w_OLS_SGD_TEST))\n",
    "print(stat_tools.MSE(z_train,X_train_scaled @ w_OLS_SGD))\n",
    "print(stat_tools.MSE(z_test,X_test_scaled @ w_OLS_Analytic))\n",
    "print(stat_tools.MSE(z_test,X_test_scaled @ w_OLS_SGD_TEST))\n",
    "print(stat_tools.MSE(z_test,X_test_scaled @ w_OLS_SGD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
